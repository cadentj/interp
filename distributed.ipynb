{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09db4a7a-4e6a-43f8-b217-2f942d1538a3",
   "metadata": {},
   "source": [
    "# Distributed Alignment Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8374691-18f6-4841-8bb7-a255528967ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "import nnsight\n",
    "from nnsight import AbstractModel, LanguageModel, util\n",
    "# from nnsight.Module import Module\n",
    "Module = nnsight.Module\n",
    "from tqdm import trange, tqdm\n",
    "from nnsight.toolbox.optim.lora import LORA\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datasets import Dataset as hf_Dataset\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from das_utils import factual_sampler\n",
    "from das import BoundlessRotatedSpaceIntervention\n",
    "\n",
    "# For initial llama load\n",
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca7ada08-77d2-41b3-9ef1-1b341fddf377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1309c7e0964957bd509cfb0f7d4e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LanguageModel('sharpbai/alpaca-7b-merged', device_map=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f30c6f4-48ec-4ec2-baa1-5f15bc502cbe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "n_tokens = 10\n",
    "epochs = 1\n",
    "answer = \"Paris\"\n",
    "answer_tokens = model.tokenizer(answer)\n",
    "answer_token = answer_tokens[\"input_ids\"][0]\n",
    "\n",
    "lora = LORA(model.transformer.h[0].mlp, 10)\n",
    "\n",
    "optimizer = torch.optim.AdamW(lora.parameters(), lr=.1)\n",
    "dataset = [[\" \".join([\"_\"] * n_tokens), answer_token]] * 100\n",
    "dataloader = DataLoader(dataset, batch_size=10)\n",
    "\n",
    "\n",
    "lossfn = util.cross_entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7f74df8-b862-4d6a-84a1-efb605717836",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "  0\n",
      "Parameter containing:\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], requires_grad=True)\n",
      "tensor(nan, grad_fn=<MeanBackward1>)\n",
      "  1\n",
      "Parameter containing:\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], requires_grad=True)\n",
      "tensor(nan, grad_fn=<MeanBackward1>)\n",
      "  2\n",
      "Parameter containing:\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], requires_grad=True)\n",
      "tensor(nan, grad_fn=<MeanBackward1>)\n",
      "  3\n",
      "Parameter containing:\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], requires_grad=True)\n",
      "tensor(nan, grad_fn=<MeanBackward1>)\n",
      "  4\n",
      "Parameter containing:\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], requires_grad=True)\n",
      "tensor(nan, grad_fn=<MeanBackward1>)\n",
      "  5\n",
      "Parameter containing:\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], requires_grad=True)\n",
      "tensor(nan, grad_fn=<MeanBackward1>)\n",
      "  6\n",
      "Parameter containing:\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], requires_grad=True)\n",
      "tensor(nan, grad_fn=<MeanBackward1>)\n",
      "  7\n",
      "Parameter containing:\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], requires_grad=True)\n",
      "tensor(nan, grad_fn=<MeanBackward1>)\n",
      "  8\n",
      "Parameter containing:\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], requires_grad=True)\n",
      "tensor(nan, grad_fn=<MeanBackward1>)\n",
      "  9\n",
      "Parameter containing:\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], requires_grad=True)\n",
      "tensor(nan, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(epoch)\n",
    "\n",
    "    for i, (inputs, targets) in enumerate(dataloader):\n",
    "        print(f\"  {i}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with model.forward(inference=False) as runner:\n",
    "            with runner.invoke(inputs) as invoker:\n",
    "\n",
    "                lora()\n",
    "    \n",
    "                logits = model.lm_head.output.save()\n",
    "\n",
    "        print(lora.WA)\n",
    "        loss = lossfn(logits.value[:, -1], targets)\n",
    "        print(loss)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70650317-f4ce-4786-92ca-c29452e0a415",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _!\n"
     ]
    }
   ],
   "source": [
    "with model.generate() as generator:\n",
    "    with generator.invoke(dataset[0][0]) as invoker:\n",
    "        pass\n",
    "\n",
    "print(model.tokenizer.decode(generator.output[0]))\n",
    "\n",
    "\n",
    "with model.generate() as generator:\n",
    "    with generator.invoke(dataset[0][0]) as invoker:\n",
    "        lora()\n",
    "\n",
    "print(model.tokenizer.decode(generator.output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e3ca1d3-43ab-410f-8b05-d43664b57476",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prealign = factual_sampler(model.tokenizer, 5000, game=\"pricing_tag\")\n",
    "\n",
    "prealign_dataset = hf_Dataset.from_dict(\n",
    "    {\"input_ids\": raw_prealign[0], \"labels\": raw_prealign[1]})\n",
    "prealign_dataset.set_format('torch', columns=['input_ids','labels'])\n",
    "prealign_dataloader = DataLoader(\n",
    "    prealign_dataset, batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67a9b667-4f7c-4cec-8da2-f2c48f706a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "prealign_input_batches = torch.split(prealign_dataset[\"input_ids\"], int(5000/1000), dim=0)\n",
    "prealign_labels_batches = torch.split(prealign_dataset['labels'][:,-1], int(5000/1000), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "566f76ee-6fa1-4b61-b1e6-d6c004e4eacc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8241 8241\n",
      "8241 13\n",
      "8241 8241\n",
      "3782 3782\n",
      "8241 8241\n",
      "8241 8241\n",
      "8241 3782\n",
      "8241 8241\n",
      "8241 8241\n",
      "8241 13\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    with model.forward() as runner:\n",
    "        with runner.invoke(raw_prealign[0][i]) as invoker: \n",
    "            out = model.lm_head.output[:,-1,:].save()\n",
    "\n",
    "    with model.generate(max_new_tokens=1) as generator:\n",
    "        with generator.invoke(raw_prealign[0][i]) as invoker: \n",
    "            pass\n",
    "    \n",
    "    out = out.value\n",
    "    val = out.softmax(dim=-1).argmax()\n",
    "\n",
    "    gen_out = generator.output[0][-1]\n",
    "    \n",
    "    print(val.item(), gen_out.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0acb1c39-ce84-4d51-8d87-453f96f39a38",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlogits\u001b[49m\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logits' is not defined"
     ]
    }
   ],
   "source": [
    "logits.value.softmax(dim=-1).argmax(dim=-1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26c8377e-08db-408d-a083-7d24a7c92aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(99)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d658a931-3b51-48f0-b643-a25b4ee5b30a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "20it [00:14,  1.38it/s]\n"
     ]
    }
   ],
   "source": [
    "per_batch_acc = []\n",
    "per_batch_res = []\n",
    "total_correct = 0\n",
    "\n",
    "for i, batch in tqdm(enumerate(prealign_input_batches)):\n",
    "    with model.forward() as runner:\n",
    "        with runner.invoke(batch) as invoker:\n",
    "            logits = model.lm_head.output[:,-1,:].save()\n",
    "            \n",
    "    # out = generator.output[:,-1].cpu()\n",
    "\n",
    "    pred = logits.value.softmax(dim=-1).argmax(dim=-1).cpu()\n",
    "    correct = (pred==prealign_labels_batches[i]).sum()\n",
    "    per_batch_acc.append(correct)\n",
    "    total_correct += (correct)\n",
    "\n",
    "    if i == 20: break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c15601b2-a7cb-4e4d-8988-a635090590fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m rotatedSpaceIntervention \u001b[38;5;241m=\u001b[39m BoundlessRotatedSpaceIntervention(model_hidden_dim)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# need to define train dataloader first\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m t_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_dataloader\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      7\u001b[0m warm_up_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m t_total\n\u001b[1;32m      9\u001b[0m optimizer_params \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "model_hidden_dim = 768\n",
    "rotatedSpaceIntervention = BoundlessRotatedSpaceIntervention(model_hidden_dim)\n",
    "\n",
    "# need to define train dataloader first\n",
    "\n",
    "t_total = int(len(train_dataloader) * 3)\n",
    "warm_up_steps = 0.1 * t_total\n",
    "\n",
    "optimizer_params = []\n",
    "optimizer_params += [{'params': rotatedSpaceIntervention.rotate_layer.parameters()}]\n",
    "optimizer_params += [{'params': rotatedSpaceIntervention.intervention_boundaries, 'lr': 1e-2}]\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    optimizer_params,\n",
    "    lr=1e-3\n",
    ")\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warm_up_steps,\n",
    "    num_training_steps=t_total\n",
    ")\n",
    "\n",
    "epochs = 3\n",
    "gradient_accumulation_steps = 4\n",
    "total_step = 0\n",
    "target_total_step = len(train_dataloader) * epochs\n",
    "temperature_start = 50.0\n",
    "temperature_end = 0.1\n",
    "temperature_schedule = torch.linspace(\n",
    "    temperature_start, temperature_end, target_total_step\n",
    ").to(torch.bfloat16).to(\"cuda\")\n",
    "\n",
    "# is this correct\n",
    "rotatedSpaceIntervention.set_temperature(temperature_schedule[total_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "11379264-fee9-4637-8c23-c71a3f25b60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0: 100%|██████████| 625/625 [00:00<00:00, 1946.75it/s]\n",
      "Epoch: 1: 100%|██████████| 625/625 [00:00<00:00, 1828.70it/s]\n",
      "Epoch: 2: 100%|██████████| 625/625 [00:00<00:00, 2137.86it/s]\n",
      "Epoch: 100%|██████████| 3/3 [00:00<00:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_iterator = trange(\n",
    "    0, int(epochs), desc=\"Epoch\"\n",
    ")\n",
    "number = 0\n",
    "for epoch in train_iterator:\n",
    "    epoch_iterator = tqdm(\n",
    "        prealign_dataloader, desc=f\"Epoch: {epoch}\", position=0, leave=True\n",
    "    )\n",
    "    for step, inputs in enumerate(epoch_iterator):\n",
    "        number  += 1\n",
    "\n",
    "print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6bb752-5aec-4fe1-8b61-da94c5028cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignable.model.train() # train enables drop-off but no grads\n",
    "print(\"llama trainable parameters: \", count_parameters(alignable.model))\n",
    "print(\"intervention trainable parameters: \", alignable.count_parameters())\n",
    "train_iterator = trange(\n",
    "    0, int(epochs), desc=\"Epoch\"\n",
    ")\n",
    "for epoch in train_iterator:\n",
    "    epoch_iterator = tqdm(\n",
    "        train_dataloader, desc=f\"Epoch: {epoch}\", position=0, leave=True\n",
    "    )\n",
    "    for step, inputs in enumerate(epoch_iterator):\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(\"cuda\")\n",
    "        b_s = inputs[\"input_ids\"].shape[0]\n",
    "        _, counterfactual_outputs = alignable(\n",
    "            {\"input_ids\": inputs[\"input_ids\"]},\n",
    "            [{\"input_ids\": inputs[\"source_input_ids\"]}],\n",
    "            {\"sources->base\": ([[[80]]*b_s], [[[80]]*b_s])} # swap 80th token\n",
    "        )\n",
    "        eval_metrics = compute_metrics(\n",
    "            [counterfactual_outputs.logits], [inputs['labels']]\n",
    "        )\n",
    "        \n",
    "        # loss and backprop\n",
    "        loss = calculate_loss(\n",
    "            counterfactual_outputs.logits, inputs[\"labels\"]\n",
    "        )\n",
    "        loss_str = round(loss.item(), 2)\n",
    "        epoch_iterator.set_postfix({'loss': loss_str, 'acc': eval_metrics[\"accuracy\"]})\n",
    "        \n",
    "        if gradient_accumulation_steps > 1:\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "        if total_step % gradient_accumulation_steps == 0:\n",
    "            if not (gradient_accumulation_steps > 1 and total_step == 0):\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                alignable.set_zero_grad()\n",
    "                alignable.set_temperature(temperature_schedule[total_step])\n",
    "        total_step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
