{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "\n",
    "model = LanguageModel(\"openai-community/gpt2-xl\")\n",
    "\n",
    "REMOTE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664e8cc0002c2d9aa91d0eea - RECEIVED: Your job has been received and is waiting approval.\n",
      "664e8cc0002c2d9aa91d0eea - APPROVED: Your job was approved and is waiting to be run.\n",
      "664e8cc0002c2d9aa91d0eea - COMPLETED: Your job has been completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading result: 100%|██████████| 1.75k/1.75k [00:00<00:00, 32.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "from utils import get_request\n",
    "\n",
    "decoder = lambda x : model.lm_head(model.transformer.ln_f(x))\n",
    "\n",
    "\n",
    "with model.trace(\"The Eiffel Tower is in the city of\", remote=REMOTE) as tracer:\n",
    "    results = {}\n",
    "    \n",
    "    for i, layer in enumerate(model.transformer.h):\n",
    "        output = layer.output[0]\n",
    "\n",
    "        decoded = decoder(output)\n",
    "\n",
    "        probs, tokens = decoded.softmax(-1).max(-1).save()\n",
    "\n",
    "        results[i] = {\n",
    "            \"probs\" : probs.tolist().save(),\n",
    "            \"tokens\" : tokens.tolist().save()\n",
    "        }\n",
    "\n",
    "        break\n",
    "\n",
    "    request = get_request(tracer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"eiffel_tower.json\", \"w\") as f:\n",
    "    json.dump(request.model_dump_json(), f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '664e8ecbb6a68fc7ea14c0c9', 'status': 'APPROVED', 'description': 'Your job was approved and is waiting to be run.', 'received': '2024-05-23 00:33:15.477050', 'session_id': 'ebBzUjECyKK05lshABpX'}\n",
      "{'id': '664e8ecbb6a68fc7ea14c0c9', 'status': 'COMPLETED', 'description': 'Your job has been completed.', 'received': '2024-05-23 00:33:15.477050', 'session_id': 'ebBzUjECyKK05lshABpX'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading result: 100%|██████████| 1.75k/1.75k [00:00<00:00, 16.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from nnsight import CONFIG\n",
    "\n",
    "import socketio\n",
    "\n",
    "with socketio.SimpleClient(reconnection_attempts=10) as sio:\n",
    "\n",
    "    sio.connect(\n",
    "        f\"wss://{CONFIG.API.HOST}\",\n",
    "        socketio_path=\"/ws/socket.io\",\n",
    "        transports=[\"websocket\"],\n",
    "        wait_timeout=10,\n",
    "    )\n",
    "\n",
    "    # Give request session ID so server knows to respond via websockets to us.\n",
    "    request.session_id = sio.sid\n",
    "\n",
    "    url = f\"https://{CONFIG.API.HOST}/request\"\n",
    "\n",
    "    response = requests.post(\n",
    "        f\"https://{CONFIG.API.HOST}/request\",\n",
    "        json=request.model_dump(exclude=[\"id\", \"received\"]),\n",
    "        headers={\"ndif-api-key\": CONFIG.API.APIKEY},\n",
    "    )\n",
    "\n",
    "    _exit = False\n",
    "    value = None\n",
    "    while True:\n",
    "        response = sio.receive()\n",
    "\n",
    "        for i in response:\n",
    "            if type(i) == dict:\n",
    "                print(i)\n",
    "                if i['status'] == \"COMPLETED\":\n",
    "                    _exit = True\n",
    "                    value = i['id']\n",
    "                    break\n",
    "        if _exit:\n",
    "            break\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import io\n",
    "result_bytes = io.BytesIO()\n",
    "result_bytes.seek(0)\n",
    "\n",
    "with requests.get(url=f\"https://{CONFIG.API.HOST}/result/{value}\", stream=True) as stream:\n",
    "    # Total size of incoming data.\n",
    "    total_size = float(stream.headers[\"Content-length\"])\n",
    "\n",
    "    with tqdm(\n",
    "        total=total_size,\n",
    "        unit=\"B\",\n",
    "        unit_scale=True,\n",
    "        desc=\"Downloading result\",\n",
    "    ) as progress_bar:\n",
    "        # chunk_size=None so server determines chunk size.\n",
    "        for data in stream.iter_content(chunk_size=None):\n",
    "            progress_bar.update(len(data))\n",
    "            result_bytes.write(data)\n",
    "\n",
    "    # Move cursor to beginning of bytes.\n",
    "    result_bytes.seek(0)\n",
    "\n",
    "    out = torch.load(result_bytes, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '664e8ecbb6a68fc7ea14c0c9',\n",
       " 'saves': {'proxy_call_3': (tensor([[0.0017, 0.0533, 0.0912, 0.0529, 0.4096, 0.0132, 0.0217, 0.0253, 0.6327,\n",
       "            0.0304]], requires_grad=True),\n",
       "   tensor([[10562, 26483, 22402,  1098,  8765,   783,  1502,   976,  6745,   262]])),\n",
       "  'proxy_call_4': [[0.0016897746827453375,\n",
       "    0.05329510569572449,\n",
       "    0.09117957204580307,\n",
       "    0.052862223237752914,\n",
       "    0.40957528352737427,\n",
       "    0.013241843320429325,\n",
       "    0.021667778491973877,\n",
       "    0.025325456634163857,\n",
       "    0.6326640844345093,\n",
       "    0.030422642827033997]],\n",
       "  'proxy_call_5': [[10562,\n",
       "    26483,\n",
       "    22402,\n",
       "    1098,\n",
       "    8765,\n",
       "    783,\n",
       "    1502,\n",
       "    976,\n",
       "    6745,\n",
       "    262]]}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "# Decode tokens\n",
    "decoded_tokens = {}\n",
    "for key, value in results.items():\n",
    "    decoded_tokens[key] = [model.tokenizer.decode([token]) for token in value['tokens'][0]]\n",
    "\n",
    "# Plotting the table\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Set up the colormap\n",
    "norm = mcolors.Normalize(vmin=0, vmax=1)\n",
    "cmap = plt.cm.get_cmap('coolwarm')\n",
    "\n",
    "# Create the table data\n",
    "table_data = []\n",
    "for key, value in results.items():\n",
    "    row = []\n",
    "    for token, prob in zip(decoded_tokens[key], value['probs'][0]):\n",
    "        color = cmap(norm(prob))\n",
    "        row.append((token, color))\n",
    "    table_data.append(row)\n",
    "\n",
    "# Create the table\n",
    "table = ax.table(\n",
    "    cellText=[[cell[0] for cell in row] for row in table_data],\n",
    "    cellColours=[[cell[1] for cell in row] for row in table_data],\n",
    "    loc='center',\n",
    "    cellLoc='center',\n",
    ")\n",
    "\n",
    "# Remove axes\n",
    "ax.axis('off')\n",
    "\n",
    "# Adjust layout to make the table fit better\n",
    "plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
