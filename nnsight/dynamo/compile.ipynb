{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/u/caden/.conda/envs/interp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from nnsight import LanguageModel\n",
    "from nnsight.envoy import Envoy\n",
    "from nnsight.util import WrapperModule\n",
    "import torch\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "from transformers.utils import fx as tfx\n",
    "import torch.fx as fx\n",
    "from torch.fx import replace_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4126541203.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    _ = with model.trace(\"a\", trace=False)\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model = LanguageModel(\"gpt2\", device_map=\"cuda:0\", dispatch=True)\n",
    "\n",
    "_ = model.trace(\"a\", trace=False)\n",
    "    \n",
    "attention = model._model.transformer.h[3].attn\n",
    "attention_envoy = model._envoy.transformer.h[3].attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Attention(\n",
       "  (c_attn): Conv1D()\n",
       "  (c_proj): Conv1D()\n",
       "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (output_wrapper): WrapperModule()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper_module = WrapperModule()\n",
    "wrapper_name = 'output_wrapper'\n",
    "\n",
    "setattr(attention, wrapper_name, wrapper_module)\n",
    "\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Count: 6\n",
      "Graph Break Count: 5\n",
      "Op Count: 13\n",
      "Break Reasons:\n",
      "  Break Reason 1:\n",
      "    Reason: call_function UserDefinedObjectVariable(_hook) [UnspecializedNNModuleVariable(Dropout), TupleVariable(), ConstDictVariable(), TensorVariable()] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py, line 331 in resume_in_forward>\n",
      "      <FrameSummary file /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py, line 212 in _attn>\n",
      "      <FrameSummary file /share/u/caden/.local/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1572 in _call_impl>\n",
      "  Break Reason 2:\n",
      "    Reason: call_function UserDefinedObjectVariable(_hook) [UnspecializedNNModuleVariable(Dropout), TupleVariable(), ConstDictVariable(), TensorVariable()] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py, line 212 in _attn>\n",
      "      <FrameSummary file /share/u/caden/.local/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1572 in _call_impl>\n",
      "  Break Reason 3:\n",
      "    Reason: call_function UserDefinedObjectVariable(_hook) [NNModuleVariable(), TupleVariable(), ConstDictVariable(), TensorVariable()] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py, line 334 in resume_in_forward>\n",
      "      <FrameSummary file /share/u/caden/.local/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1572 in _call_impl>\n",
      "Ops per Graph:\n",
      "  Ops 1:\n",
      "    <built-in method addmm of type object at 0x7f92a6e838a0>\n",
      "  Ops 2:\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "  Ops 3:\n",
      "    <built-in method matmul of type object at 0x7f92a6e838a0>\n",
      "    <built-in method full of type object at 0x7f92a6e838a0>\n",
      "    <built-in function truediv>\n",
      "    <built-in function getitem>\n",
      "    <built-in method full of type object at 0x7f92a6e838a0>\n",
      "    <built-in method where of type object at 0x7f92a6e838a0>\n",
      "    <function softmax at 0x7f91c400d620>\n",
      "  Ops 4:\n",
      "    <built-in method matmul of type object at 0x7f92a6e838a0>\n",
      "  Ops 5:\n",
      "  Ops 6:\n",
      "    <built-in method addmm of type object at 0x7f92a6e838a0>\n",
      "Out Guards:\n",
      "  Guard 1:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 2:\n",
      "    Name: \"L['self'].c_attn\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 3:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: BACKEND_MATCH\n",
      "    Guard Types: ['BACKEND_MATCH']\n",
      "    Code List: ['(___skip_backend_check() or ___current_backend() == ___lookup_backend(140264391666368))']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 4:\n",
      "    Name: \"L['encoder_hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['encoder_hidden_states'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 5:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 6:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7f91d93b2750; to 'FakeTensor' at 0x7f91d9395f10>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91c349e160; to 'torch._C._TensorMeta' at 0x66442a0 (FakeTensor)>\n",
      "  Guard 7:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: CONFIG_HASH_MATCH\n",
      "    Guard Types: ['CONFIG_HASH_MATCH']\n",
      "    Code List: [\"___compile_config_hash() == 'b6d122f35ae89a13d305ef10804fbcea'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 8:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 9:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: HAS_GRAPH_BREAK\n",
      "    Guard Types: ['HAS_GRAPH_BREAK']\n",
      "    Code List: ['not ___needs_nopython()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 10:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 140264392745360)\"]\n",
      "    Object Weakref: <weakref at 0x7f91b41dbd30; to 'GPT2Attention' at 0x7f91d94de190>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91e04d0130; to 'type' at 0xa794fe0 (GPT2Attention)>\n",
      "  Guard 11:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 12:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 13:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 14:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: BACKEND_MATCH\n",
      "    Guard Types: ['BACKEND_MATCH']\n",
      "    Code List: ['(___skip_backend_check() or ___current_backend() == ___lookup_backend(140264391666368))']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 15:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 16:\n",
      "    Name: \"L['self'].nf\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 17:\n",
      "    Name: \"L['x']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['x'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7f91d93b2750; to 'FakeTensor' at 0x7f91d9395f10>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91c349e160; to 'torch._C._TensorMeta' at 0x66442a0 (FakeTensor)>\n",
      "  Guard 18:\n",
      "    Name: \"L['self'].bias\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 19:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: CONFIG_HASH_MATCH\n",
      "    Guard Types: ['CONFIG_HASH_MATCH']\n",
      "    Code List: [\"___compile_config_hash() == 'b6d122f35ae89a13d305ef10804fbcea'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 20:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 21:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 140264392745488)\"]\n",
      "    Object Weakref: <weakref at 0x7f91b4276520; to 'Conv1D' at 0x7f91d94de210>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91e06894e0; to 'type' at 0x9901c10 (Conv1D)>\n",
      "  Guard 22:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 23:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 24:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 25:\n",
      "    Name: \"L['self'].weight\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 26:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 27:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: BACKEND_MATCH\n",
      "    Guard Types: ['BACKEND_MATCH']\n",
      "    Code List: ['(___skip_backend_check() or ___current_backend() == ___lookup_backend(140264391666368))']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 28:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 29:\n",
      "    Name: \"G['detect_fake_mode']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 30:\n",
      "    Name: \"L['input']\"\n",
      "    Source: local\n",
      "    Create Function: LIST_LENGTH\n",
      "    Guard Types: ['LIST_LENGTH']\n",
      "    Code List: [\"___check_type_id(L['input'], 8810304)\", \"len(L['input']) == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7f92c39df6a0; to 'type' at 0x866f40 (tuple)>\n",
      "  Guard 31:\n",
      "    Name: \"L['input'][0]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['input'][0], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7f91d93b2750; to 'FakeTensor' at 0x7f91d9395f10>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91c349e160; to 'torch._C._TensorMeta' at 0x66442a0 (FakeTensor)>\n",
      "  Guard 32:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: CONFIG_HASH_MATCH\n",
      "    Guard Types: ['CONFIG_HASH_MATCH']\n",
      "    Code List: [\"___compile_config_hash() == 'b6d122f35ae89a13d305ef10804fbcea'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 33:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 34:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: HAS_GRAPH_BREAK\n",
      "    Guard Types: ['HAS_GRAPH_BREAK']\n",
      "    Code List: ['not ___needs_nopython()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 35:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 36:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 37:\n",
      "    Name: \"L['layer_past']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['layer_past'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 38:\n",
      "    Name: \"L['attention_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['attention_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 39:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 40:\n",
      "    Name: \"L['use_cache']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['use_cache'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7f92c39f7ce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 41:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: BACKEND_MATCH\n",
      "    Guard Types: ['BACKEND_MATCH']\n",
      "    Code List: ['(___skip_backend_check() or ___current_backend() == ___lookup_backend(140264391666368))']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 42:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 43:\n",
      "    Name: \"L['self'].split_size\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 44:\n",
      "    Name: \"L['self'].head_dim\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 45:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: CONFIG_HASH_MATCH\n",
      "    Guard Types: ['CONFIG_HASH_MATCH']\n",
      "    Code List: [\"___compile_config_hash() == 'b6d122f35ae89a13d305ef10804fbcea'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 46:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 47:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7f91adea83b0; to 'FakeTensor' at 0x7f91b438ba70>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91c349e160; to 'torch._C._TensorMeta' at 0x66442a0 (FakeTensor)>\n",
      "  Guard 48:\n",
      "    Name: \"L['self'].reorder_and_upcast_attn\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 49:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 140264392745360)\"]\n",
      "    Object Weakref: <weakref at 0x7f91b41dbd30; to 'GPT2Attention' at 0x7f91d94de190>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91e04d0130; to 'type' at 0xa794fe0 (GPT2Attention)>\n",
      "  Guard 50:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 51:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 52:\n",
      "    Name: \"L['self'].num_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 53:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: HAS_GRAPH_BREAK\n",
      "    Guard Types: ['HAS_GRAPH_BREAK']\n",
      "    Code List: ['not ___needs_nopython()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 54:\n",
      "    Name: \"L['head_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['head_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 55:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 56:\n",
      "    Name: \"G['torch'].finfo\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 57:\n",
      "    Name: \"L['self'].scale_attn_weights\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 58:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 59:\n",
      "    Name: \"L['attention_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['attention_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 60:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: BACKEND_MATCH\n",
      "    Guard Types: ['BACKEND_MATCH']\n",
      "    Code List: ['(___skip_backend_check() or ___current_backend() == ___lookup_backend(140264391666368))']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 61:\n",
      "    Name: \"L['self'].is_cross_attention\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 62:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: HAS_GRAPH_BREAK\n",
      "    Guard Types: ['HAS_GRAPH_BREAK']\n",
      "    Code List: ['not ___needs_nopython()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 63:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 64:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 65:\n",
      "    Name: \"L['query']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['query'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7f91aded49f0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91c349e160; to 'torch._C._TensorMeta' at 0x66442a0 (FakeTensor)>\n",
      "  Guard 66:\n",
      "    Name: \"G['nn'].functional\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 67:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 68:\n",
      "    Name: \"L['self'].attn_dropout\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 69:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 140264392745360)\"]\n",
      "    Object Weakref: <weakref at 0x7f91b41dbd30; to 'GPT2Attention' at 0x7f91d94de190>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91e04d0130; to 'type' at 0xa794fe0 (GPT2Attention)>\n",
      "  Guard 70:\n",
      "    Name: \"L['value']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['value'], 107233952)\"]\n",
      "    Object Weakref: <weakref at 0x7f91adeb9940; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91c349e160; to 'torch._C._TensorMeta' at 0x66442a0 (FakeTensor)>\n",
      "  Guard 71:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 72:\n",
      "    Name: \"G['nn']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 73:\n",
      "    Name: \"L['self'].bias\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 74:\n",
      "    Name: \"L['key']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['key'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7f91aded4400; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91c349e160; to 'torch._C._TensorMeta' at 0x66442a0 (FakeTensor)>\n",
      "  Guard 75:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: CONFIG_HASH_MATCH\n",
      "    Guard Types: ['CONFIG_HASH_MATCH']\n",
      "    Code List: [\"___compile_config_hash() == 'b6d122f35ae89a13d305ef10804fbcea'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 76:\n",
      "    Name: \"L['value']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['value'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7f91adeb9940; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91c349e160; to 'torch._C._TensorMeta' at 0x66442a0 (FakeTensor)>\n",
      "  Guard 77:\n",
      "    Name: \"L['self'].scale_attn_by_inverse_layer_idx\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 78:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 79:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: BACKEND_MATCH\n",
      "    Guard Types: ['BACKEND_MATCH']\n",
      "    Code List: ['(___skip_backend_check() or ___current_backend() == ___lookup_backend(140264391666368))']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 80:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 81:\n",
      "    Name: \"G['detect_fake_mode']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 82:\n",
      "    Name: \"L['input']\"\n",
      "    Source: local\n",
      "    Create Function: LIST_LENGTH\n",
      "    Guard Types: ['LIST_LENGTH']\n",
      "    Code List: [\"___check_type_id(L['input'], 8810304)\", \"len(L['input']) == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7f92c39df6a0; to 'type' at 0x866f40 (tuple)>\n",
      "  Guard 83:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: CONFIG_HASH_MATCH\n",
      "    Guard Types: ['CONFIG_HASH_MATCH']\n",
      "    Code List: [\"___compile_config_hash() == 'b6d122f35ae89a13d305ef10804fbcea'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 84:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 85:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: HAS_GRAPH_BREAK\n",
      "    Guard Types: ['HAS_GRAPH_BREAK']\n",
      "    Code List: ['not ___needs_nopython()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 86:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 87:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: ['SHAPE_ENV', 'SHAPE_ENV']\n",
      "    Code List: [\"L['input'][0].stride()[0] == L['input'][0].size()[1]\", \"2 <= L['input'][0].size()[1]\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 88:\n",
      "    Name: \"L['input'][0]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['input'][0], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7f91b40b7150; to 'FakeTensor' at 0x7f91ade047d0>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91c349e160; to 'torch._C._TensorMeta' at 0x66442a0 (FakeTensor)>\n",
      "  Guard 89:\n",
      "    Name: \"L['value']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['value'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7f91adeb9940; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91c349e160; to 'torch._C._TensorMeta' at 0x66442a0 (FakeTensor)>\n",
      "  Guard 90:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 91:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: BACKEND_MATCH\n",
      "    Guard Types: ['BACKEND_MATCH']\n",
      "    Code List: ['(___skip_backend_check() or ___current_backend() == ___lookup_backend(140264391666368))']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 92:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 93:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7f91b40b7150; to 'FakeTensor' at 0x7f91ade047d0>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91c349e160; to 'torch._C._TensorMeta' at 0x66442a0 (FakeTensor)>\n",
      "  Guard 94:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: CONFIG_HASH_MATCH\n",
      "    Guard Types: ['CONFIG_HASH_MATCH']\n",
      "    Code List: [\"___compile_config_hash() == 'b6d122f35ae89a13d305ef10804fbcea'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 95:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 96:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 97:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 98:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 99:\n",
      "    Name: \"L['head_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['head_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 100:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 101:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: BACKEND_MATCH\n",
      "    Guard Types: ['BACKEND_MATCH']\n",
      "    Code List: ['(___skip_backend_check() or ___current_backend() == ___lookup_backend(140264391666368))']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 102:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 103:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: LIST_LENGTH\n",
      "    Guard Types: ['LIST_LENGTH']\n",
      "    Code List: [\"___check_type_id(L['___stack0'], 8810304)\", \"len(L['___stack0']) == 2\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7f92c39df6a0; to 'type' at 0x866f40 (tuple)>\n",
      "  Guard 104:\n",
      "    Name: \"L['self'].head_dim\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 105:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: CONFIG_HASH_MATCH\n",
      "    Guard Types: ['CONFIG_HASH_MATCH']\n",
      "    Code List: [\"___compile_config_hash() == 'b6d122f35ae89a13d305ef10804fbcea'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 106:\n",
      "    Name: \"L['self'].c_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 107:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 108:\n",
      "    Name: \"L['___stack0'][1]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'][1], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7f91b40b7150; to 'FakeTensor' at 0x7f91ade047d0>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91c349e160; to 'torch._C._TensorMeta' at 0x66442a0 (FakeTensor)>\n",
      "  Guard 109:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 140264392745360)\"]\n",
      "    Object Weakref: <weakref at 0x7f91b41dbd30; to 'GPT2Attention' at 0x7f91d94de190>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91e04d0130; to 'type' at 0xa794fe0 (GPT2Attention)>\n",
      "  Guard 110:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 111:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 112:\n",
      "    Name: \"L['self'].num_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 113:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: HAS_GRAPH_BREAK\n",
      "    Guard Types: ['HAS_GRAPH_BREAK']\n",
      "    Code List: ['not ___needs_nopython()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 114:\n",
      "    Name: \"L['___stack0'][0]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7f91b414da80; to 'FakeTensor' at 0x7f91b415fd70>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91c349e160; to 'torch._C._TensorMeta' at 0x66442a0 (FakeTensor)>\n",
      "  Guard 115:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 116:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: BACKEND_MATCH\n",
      "    Guard Types: ['BACKEND_MATCH']\n",
      "    Code List: ['(___skip_backend_check() or ___current_backend() == ___lookup_backend(140264391666368))']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 117:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 118:\n",
      "    Name: \"L['self'].nf\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 119:\n",
      "    Name: \"L['x']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['x'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7f91b41a16c0; to 'FakeTensor' at 0x7f91b419bc50>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91c349e160; to 'torch._C._TensorMeta' at 0x66442a0 (FakeTensor)>\n",
      "  Guard 120:\n",
      "    Name: \"L['self'].bias\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 121:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: CONFIG_HASH_MATCH\n",
      "    Guard Types: ['CONFIG_HASH_MATCH']\n",
      "    Code List: [\"___compile_config_hash() == 'b6d122f35ae89a13d305ef10804fbcea'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 122:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 123:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 140264392745680)\"]\n",
      "    Object Weakref: <weakref at 0x7f91b41a2e30; to 'Conv1D' at 0x7f91d94de2d0>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91e06894e0; to 'type' at 0x9901c10 (Conv1D)>\n",
      "  Guard 124:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 125:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 126:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 127:\n",
      "    Name: \"L['self'].weight\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 128:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 129:\n",
      "    Name: \"L['self'].resid_dropout\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 130:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: BACKEND_MATCH\n",
      "    Guard Types: ['BACKEND_MATCH']\n",
      "    Code List: ['(___skip_backend_check() or ___current_backend() == ___lookup_backend(140264391666368))']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 131:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 132:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7f91b41a2110; to 'FakeTensor' at 0x7f91add45250>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91c349e160; to 'torch._C._TensorMeta' at 0x66442a0 (FakeTensor)>\n",
      "  Guard 133:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: CONFIG_HASH_MATCH\n",
      "    Guard Types: ['CONFIG_HASH_MATCH']\n",
      "    Code List: [\"___compile_config_hash() == 'b6d122f35ae89a13d305ef10804fbcea'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 134:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 135:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: HAS_GRAPH_BREAK\n",
      "    Guard Types: ['HAS_GRAPH_BREAK']\n",
      "    Code List: ['not ___needs_nopython()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 136:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 140264392745360)\"]\n",
      "    Object Weakref: <weakref at 0x7f91b41dbd30; to 'GPT2Attention' at 0x7f91d94de190>\n",
      "    Guarded Class Weakref: <weakref at 0x7f91e04d0130; to 'type' at 0xa794fe0 (GPT2Attention)>\n",
      "  Guard 137:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 138:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "Compile Times: TorchDynamo compilation metrics:\n",
      "Function                         Runtimes (s)\n",
      "-------------------------------  ----------------------------------------------------------------------------------------------\n",
      "_compile.<locals>.compile_inner  0.1886, 0.0209, 0.0166, 0.0078, 0.1113, 0.0656, 0.0556, 0.0116, 0.0498, 0.0133, 0.0334, 0.0044\n",
      "OutputGraph.call_user_compiler   0.0068, 0.0000, 0.0001, 0.0000, 0.0000, 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch._dynamo.reset()\n",
    "explain_output = torch._dynamo.explain(attention)(attention_envoy._fake_inputs[0][0][0])\n",
    "print(explain_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': False,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict([('bias',\n",
       "               tensor([[[[ True, False, False,  ..., False, False, False],\n",
       "                         [ True,  True, False,  ..., False, False, False],\n",
       "                         [ True,  True,  True,  ..., False, False, False],\n",
       "                         ...,\n",
       "                         [ True,  True,  True,  ...,  True, False, False],\n",
       "                         [ True,  True,  True,  ...,  True,  True, False],\n",
       "                         [ True,  True,  True,  ...,  True,  True,  True]]]], device='cuda:0')),\n",
       "              ('masked_bias', tensor(-10000., device='cuda:0'))]),\n",
       " '_non_persistent_buffers_set': {'bias', 'masked_bias'},\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks_with_kwargs': OrderedDict([(47, True)]),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('c_attn', Conv1D()),\n",
       "              ('c_proj', Conv1D()),\n",
       "              ('attn_dropout', Dropout(p=0.1, inplace=False)),\n",
       "              ('resid_dropout', Dropout(p=0.1, inplace=False)),\n",
       "              ('output_wrapper', WrapperModule())]),\n",
       " 'embed_dim': 768,\n",
       " 'num_heads': 12,\n",
       " 'head_dim': 64,\n",
       " 'split_size': 768,\n",
       " 'scale_attn_weights': True,\n",
       " 'is_cross_attention': False,\n",
       " 'scale_attn_by_inverse_layer_idx': False,\n",
       " 'layer_idx': 3,\n",
       " 'reorder_and_upcast_attn': False,\n",
       " 'pruned_heads': set(),\n",
       " '_is_hf_initialized': True}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_ : torch._subclasses.fake_tensor.FakeTensor):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/pytorch_utils.py:101, code: size_out = x.size()[:-1] + (self.nf,)\n",
      "        size = l_x_.size()\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/pytorch_utils.py:102, code: x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n",
      "        l__self___bias = self.L__self___bias\n",
      "        size_1 = l_x_.size(-1)\n",
      "        view = l_x_.view(-1, size_1);  l_x_ = size_1 = None\n",
      "        l__self___weight = self.L__self___weight\n",
      "        x = torch.addmm(l__self___bias, view, l__self___weight);  l__self___bias = view = l__self___weight = None\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/pytorch_utils.py:103, code: x = x.view(size_out)\n",
      "        x_1 = x.view((1, 1, 2304));  x = None\n",
      "        return (x_1,)\n",
      "        \n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_stack0_ : torch._subclasses.fake_tensor.FakeTensor):\n",
      "        l_stack0_ = L_stack0_\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:312, code: query, key, value = self.c_attn(hidden_states).split(self.split_size, dim=2)\n",
      "        split = l_stack0_.split(768, dim = 2);  l_stack0_ = None\n",
      "        query = split[0]\n",
      "        key = split[1]\n",
      "        value = split[2];  split = None\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:279, code: tensor = tensor.view(new_shape)\n",
      "        tensor = query.view((1, 1, 12, 64));  query = None\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:280, code: return tensor.permute(0, 2, 1, 3)  # (batch, head, seq_length, head_features)\n",
      "        query_1 = tensor.permute(0, 2, 1, 3);  tensor = None\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:279, code: tensor = tensor.view(new_shape)\n",
      "        tensor_1 = key.view((1, 1, 12, 64));  key = None\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:280, code: return tensor.permute(0, 2, 1, 3)  # (batch, head, seq_length, head_features)\n",
      "        key_1 = tensor_1.permute(0, 2, 1, 3);  tensor_1 = None\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:278, code: new_shape = tensor.size()[:-1] + (num_heads, attn_head_size)\n",
      "        size = value.size()\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:279, code: tensor = tensor.view(new_shape)\n",
      "        tensor_2 = value.view((1, 1, 12, 64));  value = None\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:280, code: return tensor.permute(0, 2, 1, 3)  # (batch, head, seq_length, head_features)\n",
      "        value_1 = tensor_2.permute(0, 2, 1, 3);  tensor_2 = None\n",
      "        return (query_1, key_1, value_1)\n",
      "        \n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, s0 : torch.SymInt, s1 : torch.SymInt, s2 : torch.SymInt, L_key_ : torch._subclasses.fake_tensor.FakeTensor, L_query_ : torch._subclasses.fake_tensor.FakeTensor, s3 : torch.SymInt, L_value_ : torch._subclasses.fake_tensor.FakeTensor):\n",
      "        l_key_ = L_key_\n",
      "        l_query_ = L_query_\n",
      "        l_value_ = L_value_\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:183, code: attn_weights = torch.matmul(query, key.transpose(-1, -2))\n",
      "        transpose = l_key_.transpose(-1, -2);  l_key_ = None\n",
      "        attn_weights = torch.matmul(l_query_, transpose);  l_query_ = transpose = None\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:187, code: [], value.size(-1) ** 0.5, dtype=attn_weights.dtype, device=attn_weights.device\n",
      "        size = l_value_.size(-1);  l_value_ = None\n",
      "        pow_1 = size ** 0.5;  size = None\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:186, code: attn_weights = attn_weights / torch.full(\n",
      "        full = torch.full([], pow_1, dtype = torch.float32, device = device(type='cuda', index=0));  pow_1 = None\n",
      "        attn_weights_1 = attn_weights / full;  attn_weights = full = None\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:197, code: causal_mask = self.bias[:, :, key_length - query_length : key_length, :key_length]\n",
      "        l__self___bias = self.L__self___bias\n",
      "        causal_mask = l__self___bias[(slice(None, None, None), slice(None, None, None), slice(0, 1, None), slice(None, 1, None))];  l__self___bias = None\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:201, code: mask_value = torch.full([], mask_value, dtype=attn_weights.dtype, device=attn_weights.device)\n",
      "        mask_value = torch.full([], -3.4028234663852886e+38, dtype = torch.float32, device = device(type='cuda', index=0))\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:202, code: attn_weights = torch.where(causal_mask, attn_weights.to(attn_weights.dtype), mask_value)\n",
      "        to = attn_weights_1.to(torch.float32);  attn_weights_1 = None\n",
      "        attn_weights_2 = torch.where(causal_mask, to, mask_value);  causal_mask = to = mask_value = None\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:208, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n",
      "        attn_weights_3 = torch.nn.functional.softmax(attn_weights_2, dim = -1);  attn_weights_2 = None\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:211, code: attn_weights = attn_weights.type(value.dtype)\n",
      "        attn_weights_4 = attn_weights_3.type(torch.float32);  attn_weights_3 = None\n",
      "        return (attn_weights_4,)\n",
      "        \n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, s0 : torch.SymInt, L_stack0_ : torch._subclasses.fake_tensor.FakeTensor, s1 : torch.SymInt, s2 : torch.SymInt, L_value_ : torch._subclasses.fake_tensor.FakeTensor):\n",
      "        attn_weights = L_stack0_\n",
      "        l_value_ = L_value_\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:218, code: attn_output = torch.matmul(attn_weights, value)\n",
      "        attn_output = torch.matmul(attn_weights, l_value_);  attn_weights = l_value_ = None\n",
      "        return (attn_output,)\n",
      "        \n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, s0 : torch.SymInt, s1 : torch.SymInt, L_stack0_0_ : torch._subclasses.fake_tensor.FakeTensor):\n",
      "        attn_output = L_stack0_0_\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:286, code: tensor = tensor.permute(0, 2, 1, 3).contiguous()\n",
      "        permute = attn_output.permute(0, 2, 1, 3);  attn_output = None\n",
      "        tensor = permute.contiguous();  permute = None\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:287, code: new_shape = tensor.size()[:-2] + (num_heads * attn_head_size,)\n",
      "        size = tensor.size()\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:288, code: return tensor.view(new_shape)\n",
      "        attn_output_1 = tensor.view((1, 1, 768));  tensor = None\n",
      "        return (attn_output_1,)\n",
      "        \n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_ : torch._subclasses.fake_tensor.FakeTensor):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/pytorch_utils.py:101, code: size_out = x.size()[:-1] + (self.nf,)\n",
      "        size = l_x_.size()\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/pytorch_utils.py:102, code: x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n",
      "        l__self___bias = self.L__self___bias\n",
      "        size_1 = l_x_.size(-1)\n",
      "        view = l_x_.view(-1, size_1);  l_x_ = size_1 = None\n",
      "        l__self___weight = self.L__self___weight\n",
      "        x = torch.addmm(l__self___bias, view, l__self___weight);  l__self___bias = view = l__self___weight = None\n",
      "        \n",
      "        # File: /share/u/caden/.local/lib/python3.11/site-packages/transformers/pytorch_utils.py:103, code: x = x.view(size_out)\n",
      "        x_1 = x.view((1, 1, 768));  x = None\n",
      "        return (x_1,)\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def custom_backend(gm: torch.fx.GraphModule, example_inputs: List[torch.Tensor]):\n",
    "\n",
    "    representation = str(gm)\n",
    "\n",
    "    gm.print_readable()\n",
    "    \n",
    "    return gm.forward\n",
    "\n",
    "torch._dynamo.reset()\n",
    "\n",
    "opt_model = torch.compile(attention, backend=custom_backend, dynamic=True)\n",
    "gm = opt_model(attention_envoy._fake_inputs[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
