{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e92fe721-b4b5-41c4-a675-8fa287291b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "import torch as t\n",
    "import einops\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from jaxtyping import Int, Float\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from rich import print\n",
    "\n",
    "import time\n",
    "\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cff01d7-a029-4d03-9601-cff28b6b7807",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "Load in the dataset of factual prompts and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0693180b-b6b3-4d8b-959c-693086f94bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://rome.baulab.info/data/dsets/known_1000.json\")\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97ec8a1c-924f-4341-b71a-4a5968b36640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>known_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>attribute</th>\n",
       "      <th>template</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prompt</th>\n",
       "      <th>relation_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Vinson Massif</td>\n",
       "      <td>Antarctica</td>\n",
       "      <td>{} is located in the continent</td>\n",
       "      <td>of Antarctica. It is the largest of the three</td>\n",
       "      <td>Vinson Massif is located in the continent of</td>\n",
       "      <td>P30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Beats Music</td>\n",
       "      <td>Apple</td>\n",
       "      <td>{} is owned by</td>\n",
       "      <td>Apple, which is also the owner of Beats Elect...</td>\n",
       "      <td>Beats Music is owned by</td>\n",
       "      <td>P127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Audible.com</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>{} is owned by</td>\n",
       "      <td>Amazon.com, Inc. or its affiliates.</td>\n",
       "      <td>Audible.com is owned by</td>\n",
       "      <td>P127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Big Bang Theory</td>\n",
       "      <td>CBS</td>\n",
       "      <td>{} premieres on</td>\n",
       "      <td>CBS on September 22.&lt;|endoftext|&gt;</td>\n",
       "      <td>The Big Bang Theory premieres on</td>\n",
       "      <td>P449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MacApp</td>\n",
       "      <td>Apple</td>\n",
       "      <td>{}, a product created by</td>\n",
       "      <td>Apple to help developers create apps for the ...</td>\n",
       "      <td>MacApp, a product created by</td>\n",
       "      <td>P178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   known_id              subject   attribute                        template  \\\n",
       "0         0        Vinson Massif  Antarctica  {} is located in the continent   \n",
       "1         1          Beats Music       Apple                  {} is owned by   \n",
       "2         2          Audible.com      Amazon                  {} is owned by   \n",
       "3         3  The Big Bang Theory         CBS                 {} premieres on   \n",
       "4         4               MacApp       Apple        {}, a product created by   \n",
       "\n",
       "                                          prediction  \\\n",
       "0      of Antarctica. It is the largest of the three   \n",
       "1   Apple, which is also the owner of Beats Elect...   \n",
       "2                Amazon.com, Inc. or its affiliates.   \n",
       "3                  CBS on September 22.<|endoftext|>   \n",
       "4   Apple to help developers create apps for the ...   \n",
       "\n",
       "                                         prompt relation_id  \n",
       "0  Vinson Massif is located in the continent of         P30  \n",
       "1                       Beats Music is owned by        P127  \n",
       "2                       Audible.com is owned by        P127  \n",
       "3              The Big Bang Theory premieres on        P449  \n",
       "4                  MacApp, a product created by        P178  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e71ad0-47a5-485f-b3c5-2ef3b3dd503a",
   "metadata": {},
   "source": [
    "Write a function to sample random prompts and their answers from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30c92e3d-0af1-471c-9c8b-24dcebc49701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_prompts(frame: pd.DataFrame, number: Int, prepend_space=False):\n",
    "    intermediate_frame = df.sample(n=number, random_state=10)\n",
    "    intermediate_frame = intermediate_frame[[\"subject\", \"attribute\", \"prompt\", \"template\"]]\n",
    "\n",
    "    prompts = list(intermediate_frame.prompt)\n",
    "    answers = list(intermediate_frame.attribute)\n",
    "\n",
    "    if prepend_space:\n",
    "        answers = [\" \" + a for a in answers]\n",
    "\n",
    "    return prompts, answers, intermediate_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60fd23b8-0dc2-41a1-8e55-8f892ab1c1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = LanguageModel(\"gpt2\", device_map=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c769325-3c33-4ad0-9e16-6c0dda278cf3",
   "metadata": {},
   "source": [
    "## Running the Dataset\n",
    "\n",
    "Run a single prompt through the model. And observe its outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "675f0120-2b50-4a84-b794-78f8df013ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "prompts, answers, _ = aggregate_prompts(df, 1, prepend_space=True)\n",
    "\n",
    "with model.forward() as runner:\n",
    "    with runner.invoke(prompts) as invoker: \n",
    "        pass\n",
    "    \n",
    "logits = runner.output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04367cfc-a1d9-47e4-a257-12a8619adaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to test a prompt on a model and generate a textual representaiton of outputs\n",
    "def test_prompt(prompt: str, answer: str, model):\n",
    "    \n",
    "    with model.forward() as runner:\n",
    "        with runner.invoke(prompts) as invoker: \n",
    "            pass\n",
    "\n",
    "    logits = runner.output[0]\n",
    "    logits = logits[0,-1,:] # only over the final token\n",
    "    probs = logits.softmax(dim=-1)\n",
    "    \n",
    "    sorted_indices = t.argsort(probs, descending=True)\n",
    "    val = model.tokenizer(answer).input_ids[0]\n",
    "    rank = (sorted_indices == val[0]).nonzero(as_tuple=True)[0]\n",
    "    \n",
    "    print(f\"[bold]Rank: {rank.item()}        Logit: {logits[val].item():.3f} Prob: {probs[val].item():.3f} Token: |{model.tokenizer.decode(val)}|[/]\")\n",
    "    \n",
    "    for i, (tok, prob) in enumerate(zip(probs.topk(10).indices, probs.topk(10).values)):\n",
    "        print(f\"Top {i}th token. Logit: {logits[tok]:.3f} Prob: {prob:.3f} Token: |{model.tokenizer.decode(tok)}|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c801ac32-5df1-46cb-8024-8067d9c29b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-96.798</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.153</span><span style=\"font-weight: bold\"> Token: | France|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m-96.798\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m0.153\u001b[0m\u001b[1m Token: | France|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Top 0th token. Logit: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-96.798</span> Prob: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.153</span> Token: | France|\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Top 0th token. Logit: \u001b[1;36m-96.798\u001b[0m Prob: \u001b[1;36m0.153\u001b[0m Token: | France|\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Top 1th token. Logit: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-97.523</span> Prob: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.074</span> Token: | his|\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Top 1th token. Logit: \u001b[1;36m-97.523\u001b[0m Prob: \u001b[1;36m0.074\u001b[0m Token: | his|\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Top 2th token. Logit: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-97.697</span> Prob: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.062</span> Token: | the|\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Top 2th token. Logit: \u001b[1;36m-97.697\u001b[0m Prob: \u001b[1;36m0.062\u001b[0m Token: | the|\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Top 3th token. Logit: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-99.467</span> Prob: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.011</span> Token: | Italy|\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Top 3th token. Logit: \u001b[1;36m-99.467\u001b[0m Prob: \u001b[1;36m0.011\u001b[0m Token: | Italy|\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Top 4th token. Logit: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-99.475</span> Prob: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.011</span> Token: | Saint|\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Top 4th token. Logit: \u001b[1;36m-99.475\u001b[0m Prob: \u001b[1;36m0.011\u001b[0m Token: | Saint|\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Top 5th token. Logit: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-99.568</span> Prob: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.010</span> Token: | French|\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Top 5th token. Logit: \u001b[1;36m-99.568\u001b[0m Prob: \u001b[1;36m0.010\u001b[0m Token: | French|\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Top 6th token. Logit: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-99.593</span> Prob: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.009</span> Token: | Belgium|\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Top 6th token. Logit: \u001b[1;36m-99.593\u001b[0m Prob: \u001b[1;36m0.009\u001b[0m Token: | Belgium|\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Top 7th token. Logit: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-99.796</span> Prob: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.008</span> Token: | Gren|\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Top 7th token. Logit: \u001b[1;36m-99.796\u001b[0m Prob: \u001b[1;36m0.008\u001b[0m Token: | Gren|\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Top 8th token. Logit: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-99.951</span> Prob: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.007</span> Token: | Portugal|\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Top 8th token. Logit: \u001b[1;36m-99.951\u001b[0m Prob: \u001b[1;36m0.007\u001b[0m Token: | Portugal|\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Top 9th token. Logit: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-99.974</span> Prob: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.006</span> Token: | Algeria|\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Top 9th token. Logit: \u001b[1;36m-99.974\u001b[0m Prob: \u001b[1;36m0.006\u001b[0m Token: | Algeria|\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model.tokenizer(answers).input_ids[0]\n",
    "test_prompt(prompts, answers, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cefefe5-63b0-426d-b53c-5ec562f39f7a",
   "metadata": {},
   "source": [
    "### Exercise: Calculate probabilities across a batch of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fa531bc-37c4-4ad1-baf3-dc60ee235c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "prompts, answers, _ = aggregate_prompts(df, 200, prepend_space=True)\n",
    "\n",
    "with model.generate(max_new_tokens=1) as generator:\n",
    "    with generator.invoke(prompts) as invoker:\n",
    "        out = model.lm_head.output.t[-1].save()\n",
    "\n",
    "out = out.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0256e37f-c70b-4d4e-9594-b058f0e40b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0915, device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = out.softmax(dim=-1)\n",
    "indices_tensor = t.tensor([model.tokenizer.encode(a) for a in answers]).to(device)\n",
    "top_probs = t.gather(probs, 1, indices_tensor)\n",
    "top_probs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e4c84a-741e-451c-a97f-aa1daa084edd",
   "metadata": {},
   "source": [
    "Broken runs with forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "075b372f-fd2e-4fbf-89c9-318fbbda097d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Saint-Marcellin was created in the country of'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Law &amp; Order was released on'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Knowledge Graph is owned by'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Saint Valentine holds the position of the first'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Francis Blanche speaks during a news conference at the'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m'Saint-Marcellin was created in the country of'\u001b[0m,\n",
       "    \u001b[32m'Law & Order was released on'\u001b[0m,\n",
       "    \u001b[32m'Knowledge Graph is owned by'\u001b[0m,\n",
       "    \u001b[32m'Saint Valentine holds the position of the first'\u001b[0m,\n",
       "    \u001b[32m'Francis Blanche speaks during a news conference at the'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saint-Marcellin was created in the country of\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saint-Marcellin was created in the country of\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'new_out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m out_a \u001b[38;5;241m=\u001b[39m out_a\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m     10\u001b[0m out_b \u001b[38;5;241m=\u001b[39m invoker\u001b[38;5;241m.\u001b[39moutput[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnew_out\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margmax())\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(out_b[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:]\u001b[38;5;241m.\u001b[39margmax())\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m model\u001b[38;5;241m.\u001b[39mforward(prompts[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mas\u001b[39;00m invoker:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_out' is not defined"
     ]
    }
   ],
   "source": [
    "prompts, answers = aggregate_prompts(df, 100, prepend_space=True)\n",
    "\n",
    "print(prompts[0:5])\n",
    "print(prompts[0])\n",
    "\n",
    "with model.forward(prompts) as invoker:\n",
    "    out_a = model.lm_head.output.t[-1].save()\n",
    "\n",
    "out_a = out_a.value\n",
    "out_b = invoker.output[0]\n",
    "\n",
    "print(new_out[0].argmax())\n",
    "print(out_b[0,-1,:].argmax())\n",
    "\n",
    "with model.forward(prompts[0]) as invoker:\n",
    "    out_c = model.lm_head.output.t[-1].save()\n",
    "\n",
    "out_c = out_c.value\n",
    "out_d = invoker.output[0]\n",
    "\n",
    "print(out_c[0].argmax())\n",
    "print(out_d[0,-1,:].argmax())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43ed2fb-fc42-436a-9a09-58496e743729",
   "metadata": {},
   "source": [
    "# Module 2 (Activation Patching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcd86cc8-438e-4212-9f71-0dc95ddc42d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tokens(text, tokenizer):\n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer.encode(text)\n",
    "\n",
    "    # Extract first, middle, and last tokens\n",
    "    first_token = tokens[0]\n",
    "    last_token = tokens[-1]\n",
    "    \n",
    "    num_tokens = len(tokens)\n",
    "    middle_index = num_tokens // 2\n",
    "\n",
    "    if num_tokens % 2 == 0:  # Even number of tokens\n",
    "        middle_tokens = tokens[middle_index - 1: middle_index + 1]\n",
    "    else:  # Odd number of tokens\n",
    "        middle_tokens = tokens[middle_index]\n",
    "\n",
    "    return first_token, middle_tokens, last_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7e7b933-a7ab-4a77-ae3d-63ca3e999ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>attribute</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>Saint-Marcellin</td>\n",
       "      <td>France</td>\n",
       "      <td>Saint-Marcellin was created in the country of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>Law &amp; Order</td>\n",
       "      <td>NBC</td>\n",
       "      <td>Law &amp; Order was released on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Knowledge Graph</td>\n",
       "      <td>Google</td>\n",
       "      <td>Knowledge Graph is owned by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>Saint Valentine</td>\n",
       "      <td>bishop</td>\n",
       "      <td>Saint Valentine holds the position of the first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Francis Blanche</td>\n",
       "      <td>French</td>\n",
       "      <td>Francis Blanche speaks during a news conferenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>RuneScape</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>The genre played by RuneScape is a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Grand Duchy of Finland</td>\n",
       "      <td>Helsinki</td>\n",
       "      <td>Grand Duchy of Finland's capital,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>Eddy Cue</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Eddy Cue is employed by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>Co-operative Commonwealth Federation (Ontario ...</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Co-operative Commonwealth Federation (Ontario ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>Triple H</td>\n",
       "      <td>WWE</td>\n",
       "      <td>Triple H is employed by</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                subject attribute  \\\n",
       "649                                     Saint-Marcellin    France   \n",
       "375                                         Law & Order       NBC   \n",
       "248                                     Knowledge Graph    Google   \n",
       "1084                                    Saint Valentine    bishop   \n",
       "315                                     Francis Blanche    French   \n",
       "284                                           RuneScape   fantasy   \n",
       "47                               Grand Duchy of Finland  Helsinki   \n",
       "715                                            Eddy Cue     Apple   \n",
       "824   Co-operative Commonwealth Federation (Ontario ...   Toronto   \n",
       "745                                            Triple H       WWE   \n",
       "\n",
       "                                                 prompt  \n",
       "649       Saint-Marcellin was created in the country of  \n",
       "375                         Law & Order was released on  \n",
       "248                         Knowledge Graph is owned by  \n",
       "1084    Saint Valentine holds the position of the first  \n",
       "315   Francis Blanche speaks during a news conferenc...  \n",
       "284                  The genre played by RuneScape is a  \n",
       "47                    Grand Duchy of Finland's capital,  \n",
       "715                             Eddy Cue is employed by  \n",
       "824   Co-operative Commonwealth Federation (Ontario ...  \n",
       "745                             Triple H is employed by  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "537752b1-bd9f-4fe9-af58-5985443d444b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Co-operative Commonwealth Federation <span style=\"font-weight: bold\">(</span>Ontario Section<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Co-operative Commonwealth Federation \u001b[1m(\u001b[0mOntario Section\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Co-operative Commonwealth Federation <span style=\"font-weight: bold\">(</span>Ontario Section<span style=\"font-weight: bold\">)</span>'s headquarters are in\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Co-operative Commonwealth Federation \u001b[1m(\u001b[0mOntario Section\u001b[1m)\u001b[0m's headquarters are in\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df.iloc[824].subject)\n",
    "print(df.iloc[824].prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4382b590-7700-493b-8ed3-2fa2d7ad9ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Egypt\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Egypt\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Muhammad Asad\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Muhammad Asad\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">My Sister Sam\n",
       "</pre>\n"
      ],
      "text/plain": [
       "My Sister Sam\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Dan Le Batard\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Dan Le Batard\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Time Machine <span style=\"font-weight: bold\">(</span>macOS<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Time Machine \u001b[1m(\u001b[0mmacOS\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Daiki Arioka\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Daiki Arioka\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Il Postino: The Postman\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Il Postino: The Postman\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Emilia Rydberg\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Emilia Rydberg\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Patuxent Wildlife Research Center\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Patuxent Wildlife Research Center\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Francis de Sales\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Francis de Sales\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for _, line in batched_df.iterrows():\n",
    "    print(line.subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e1119165-240f-4bc6-a25e-bcd8c34ccf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "\n",
    "# Assuming the `extract_tokens` function is defined as shown earlier\n",
    "\n",
    "first = []\n",
    "middle = []\n",
    "last = []\n",
    "\n",
    "for _, line in batched_df.iterrows():\n",
    "    # Extract the tokens from the subject\n",
    "    if (line.template[0] != \"{\"):\n",
    "        first_token, middle_tokens, last_token = extract_tokens(\" \" + line.subject, model.tokenizer)\n",
    "    else: \n",
    "        first_token, middle_tokens, last_token = extract_tokens(line.subject, model.tokenizer)\n",
    "\n",
    "    # Encode the prompt\n",
    "    prompt = line.prompt\n",
    "    prompt_tokens = model.tokenizer.encode(prompt)\n",
    "    prompt_length = len(prompt_tokens)\n",
    "\n",
    "    if not isinstance(middle_tokens, list): \n",
    "        middle_tokens = [middle_tokens]\n",
    "    \n",
    "    # Find indices in the prompt and convert to negative indices\n",
    "    first_index = prompt_tokens.index(first_token)\n",
    "    last_index = prompt_tokens.index(last_token)\n",
    "    middle_indices = [(prompt_tokens.index(token_id)) for token_id in middle_tokens]\n",
    "    \n",
    "    first.append([first_index])\n",
    "    middle.append(middle_indices)\n",
    "    last.append([last_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2a1e845-8dec-464f-b796-84482055f90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [3], [2], [3], [5], [3], [9], [4], [5], [3]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eaa1ae-8189-48c4-907a-70826edf0fc5",
   "metadata": {},
   "source": [
    "### Save Clean Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "efca5e2c-2e89-432b-aa7f-df84419a0784",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts, answers, batched_df = aggregate_prompts(df, 10, prepend_space=True)\n",
    "\n",
    "clean = []\n",
    "\n",
    "with model.forward() as runner:\n",
    "    with runner.invoke(prompts) as invoker:\n",
    "        for layer in model.transformer.h:\n",
    "            clean.append(layer.output[0].save())\n",
    "\n",
    "clean = [c.value for c in clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a64b257a-1089-49fe-b9db-7aa73f259e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2AttentionAltered(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (query): WrapperModule()\n",
       "          (key): WrapperModule()\n",
       "          (value): WrapperModule()\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "48766b73-842e-46ff-8c3b-bccffeecc259",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for layer in range(12):\n",
    "\n",
    "    # First subject token\n",
    "    with model.forward() as runner:\n",
    "        with runner.invoke(prompts) as invoker:\n",
    "\n",
    "            to_patch = model.transformer.h[layer].output[0].save()\n",
    "\n",
    "            for p in to_patch:\n",
    "\n",
    "    # First subject token\n",
    "    with model.forward() as runner:\n",
    "        with runner.invoke(prompts) as invoker:\n",
    "\n",
    "            to_patch = model.transformer.h[layer].output[0].save()\n",
    "\n",
    "            for p in to_patch:\n",
    "                \n",
    "                \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "298e4589-cd6a-40d4-ac05-18216ccfb048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 15, 768])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_patch.value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd27deb5-37e6-4487-b27c-07592cea0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First subject token\n",
    "# middle subject token\n",
    "# last subject token\n",
    "# first subsequent token\n",
    "# further tokens\n",
    "# last token"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
